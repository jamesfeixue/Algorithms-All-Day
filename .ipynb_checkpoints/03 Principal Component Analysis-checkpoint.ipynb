{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Wikipedia: \n",
    "\n",
    "**Principal component analysis** (PCA) is a statistical procedure that uses an **orthogonal transformation** to convert a set of observations of possibly correlated variables (entities each of which takes on various numerical values) into a set of values of **linearly uncorrelated variables** called principal components.\n",
    "\n",
    "PCA can be thought of as fitting a p-dimensional ellipsoid to the data, where each axis of the ellipsoid represents a principal component. If some axis of the ellipsoid is small, then the variance along that axis is also small, and by omitting that axis and its corresponding principal component from our representation of the dataset, we lose only a commensurately small amount of information.\n",
    "\n",
    "Steps: \n",
    "\n",
    "1. Subtract the mean of each variable from the dataset to center the data around the origin\n",
    "2. Compute the covariance matrix of the data\n",
    "3. Calculate the eigenvalues and eigenvectors of the covariance matrix\n",
    "4. Normalize each orthogonal eigenvectors to become unit vectors\n",
    "5. Sort eigenvectrs by decreasing eigenvalues\n",
    "      - The proportion of the variance each eigenvector represents can be calculated by dividing the eigenvalue corresponding to the eigenvector by the sum of all eigenvalues\n",
    "      - Choose the top k eigenvalues\n",
    "6. Transform the samples onto the new subspace. \n",
    "\n",
    "### This Procedue is sensitive to the scaling of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44284456, 0.48855492, 0.60971564])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "def mean_vector(data): \n",
    "    \"\"\"\n",
    "    Input: an nxd matrix where: \n",
    "        n represents the number of data points\n",
    "        d represents the dimension of each data point\n",
    "    \n",
    "    Output: a d-dimensional vector representing the mean of each dimension. \n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    return np.sum(data, axis=0)/n \n",
    "    \n",
    "test_data = np.random.random((10, 3)) \n",
    "mean_vector(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.77156117e-17,  3.33066907e-17, -1.66533454e-17])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_removal(data): \n",
    "    \"\"\"\n",
    "    Input: an nxd matrix where: \n",
    "        n represents the number of data points\n",
    "        d represents the dimension of each data point\n",
    "    \n",
    "    Output: an nxd matrix with mean removed\n",
    "    \"\"\"\n",
    "    mean = mean_vector(data)\n",
    "    return np.subtract(data, mean) \n",
    "\n",
    "test_data = np.random.random((10, 3)) \n",
    "mean_vector(mean_removal(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.03731032, 0.02177103, 0.01001886],\n",
       "        [0.02177103, 0.06601152, 0.03094279],\n",
       "        [0.01001886, 0.03094279, 0.08201398]]),\n",
       " array([[0.03731032, 0.02177103, 0.01001886],\n",
       "        [0.02177103, 0.06601152, 0.03094279],\n",
       "        [0.01001886, 0.03094279, 0.08201398]]),\n",
       " array([[ 0.00000000e+00,  6.93889390e-18, -1.73472348e-18],\n",
       "        [ 6.93889390e-18,  0.00000000e+00,  3.46944695e-18],\n",
       "        [-1.73472348e-18,  3.46944695e-18,  0.00000000e+00]]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def covariance_matrix(mean_removed_data): \n",
    "    \"\"\"\n",
    "    Input: an nxd mean removed matrix where: \n",
    "        n represents the number of data points \n",
    "        d represents the dimension of each data point\n",
    "    \n",
    "    Output: dxd covariance matrix\n",
    "    \"\"\"\n",
    "    n = len(mean_removed_data)\n",
    "    transposed_data = np.transpose(mean_removed_data)\n",
    "    d = len(transposed_data)\n",
    "    matrix = np.empty((d, d))\n",
    "    \n",
    "    \"\"\"\n",
    "    Since the mean is removed: \n",
    "    instead of sum[(X_i - x_mean)(Y_i - y_mean)]/(n-1), \n",
    "    we can just do the dot product and normalize by n-1\n",
    "    \"\"\"\n",
    "    for i in range(d): \n",
    "        for j in range(d): \n",
    "            matrix[i][j] = np.dot(transposed_data[i], transposed_data[j])/(n-1)\n",
    "    return matrix \n",
    "\n",
    "test_data = np.random.random((10, 3))\n",
    "mean_removed = mean_removal(test_data)\n",
    "covariance_matrix(mean_removed), np.cov(np.transpose(mean_removed)), covariance_matrix(mean_removed)-np.cov(np.transpose(mean_removed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short Note: \n",
    "\n",
    "Everything has been easy up to this point. The next step is to find the eigenvalues and eigenvectors of the covariance matrix. \n",
    "\n",
    "- LU decomposition\n",
    "- Finding the determinant\n",
    "- Gaussian Elimination\n",
    "- Diagonalization\n",
    "- SVD\n",
    "\n",
    "Note: For large d, the covariance method here is not used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(data, dim):    \n",
    "    assert dim <= len(data[0])\n",
    "    \"\"\"\n",
    "    Let's use packages first for ease. \n",
    "    \"\"\"\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix(mean_removal(data))) \n",
    "    #note, the eigenvectors have been normalized by the package\n",
    "    # each column is the eigenvector\n",
    "\n",
    "    \"\"\"Sort eigenvectors by desceding eigenvalues\"\"\"\n",
    "    # since python automoatically sorts lists of lists by the first element: \n",
    "    # Note: calling sorted(), the python function, on numpy arrays may not work\n",
    "    # Note: np.sort() sorts on the last axis. \n",
    "    # [::-1] operates on each individual item, thus we need to transpose, apply it to reverse order, and then transpose back\n",
    "    temp = np.concatenate(([eigenvalues], eigenvectors))\n",
    "    temp = np.transpose(np.transpose(np.sort(temp))[::-1]) \n",
    "    eigenvalues_new, eigenvectors_new = temp[0], temp[1:]\n",
    "    eigenvalues_new, eigenvectors_new, eigenvectors\n",
    "\n",
    "    \"\"\"Transform the samples onto the new subspace.\"\"\"\n",
    "    \"\"\"Arbitrarily choose the first 2 dimensions\"\"\"\n",
    "    reduced_vectors = eigenvectors_new[:,0:dim]\n",
    "    final_data = np.matmul(np.transpose(reduced_vectors), np.transpose(data))\n",
    "    return np.transpose(final_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "We can test this by making each dimension of the data draw from a different gaussian with different variances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1 = np.random.normal(scale=0.5, size=100)\n",
    "feature2 = np.random.normal(scale=1.5, size=100)\n",
    "feature3 = np.random.normal(scale=2.5, size=100)\n",
    "feature4 = np.random.normal(scale=3.5, size=100)\n",
    "feature5 = np.random.normal(scale=4.5, size=100)\n",
    "\n",
    "data = np.transpose([feature1, feature2, feature3, feature4, feature5])\n",
    "transformed_data = PCA(data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111f18390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(transformed_data[:,0], transformed_data[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
